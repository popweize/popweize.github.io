---
title: YOLO v3训练自己的数据集(GPU)
description: 标注完数据，就要开始压榨GPU学习了
categories:
 - ubuntu 计算机视觉 深度学习 目标检测 YOLOV3
tags: 科技宅拯救世界
---

***

环境：Ubuntu 16.04 + CUDA10.2 + cudnn

YOLOV3主页：https://pjreddie.com/darknet/yolo/

***

**1.下载模型，并修改配置文件。**

`git clone https://github.com/pjreddie/darknet `

`cd darknet`

根据自己需求修改Makefile文件配置：

在darknet目录下

`gedit Makefile`

***

GPU=1 #如果使用GPU设置为1，CPU设置为0 

CUDNN=1  #如果使用CUDNN设置为1，否则为0 

OPENCV=1 #如果调用摄像头或显示图片，还需要设置OPENCV为1，否则为0 OPENMP=0  #如果使用OPENMP设置为1，否则为0 

DEBUG=0  #如果使用DEBUG设置为1，否则为0

***

**2.编译**

在darknet目录下

`sudo make`

若前面的路径错误或GPU算力不匹配都会报错，在服务器上跑的话将Makefile中的opencv置0，否则报错。

**3.在darknet目录下,下载预训练权重文件，运行demo**

`wget https://pjreddie.com/media/files/yolov3.weights `

运行官方demo

`./darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/dog.jpg`

（这个下载贼慢，可以直接找我要，微信在打赏页面，你懂我意思吧～～）

若demo运行成功，则说明darknet\yolov3没问题。

**4.制作自己的数据集**

新建VOC2007文件夹，并在VOC2007下新建Annotations，ImageSets和JPEGImages三个文件夹。在ImageSets下新建Main文件夹。文件目录如下所示：

![img](https://img-blog.csdnimg.cn/2018121222291633.png)

将自己的数据集图片拷贝到JPEGImages目录下。将数据集标注文件（xml文件）拷贝到Annotations目录下。

在VOC2007下新建test.py文件夹，将下面代码拷贝进去，运行后，将生成四个文件：train.txt,val.txt,test.txt和trainval.txt。



`import os `

`import random `

`trainval_percent = 0.1 `

`train_percent = 0.9 `

`xmlfilepath = 'Annotations' `

`txtsavepath = 'ImageSets\Main' `

`total_xml = os.listdir(xmlfilepath) `



`num = len(total_xml) `

`list = range(num) `

`tv = int(num * trainval_percent) `

`tr = int(tv * train_percent)` 

`trainval = random.sample(list, tv) `

`train = random.sample(trainval, tr) `



`ftrainval = open('ImageSets/Main/trainval.txt', 'w') `

`ftest = open('ImageSets/Main/test.txt', 'w') `

`ftrain = open('ImageSets/Main/train.txt', 'w') `

`fval = open('ImageSets/Main/val.txt', 'w') `



`for i in list:    `

`name = total_xml[i][:-4] + '\n' `

 `  if i in trainval: `

`       ftrainval.write(name)`

​       ` if i in train: `

​          ` ftest.write(name) `

`       else: `

​         `  fval.write(name) `

`   else: `

  `     ftrain.write(name) `

`ftrainval.close()`

`ftrain.close() `

`fval.close() `

`ftest.close()`

生成后的目录结构如下所示：

![img](https://img-blog.csdnimg.cn/20181212224232514.png)

这样自己的数据集基本做好了，接下来需要转移阵地到代码环境中去。

**5.将自己的数据集放到YOLOV3中**

在代码的darknet目录下新建VOCdevkit文件夹，然后把刚才制作的VOC2007文件夹拷贝到该文件夹下。

***

科普一下：YOLOV3的label标注的一行五个数分别代表类别（从 0 开始编号）， BoundingBox 中心 X 坐标，中心 Y 坐标，宽，高。这些坐标都是 0～1 的相对坐标。

***

和我们刚才标注的label不同，因此我们需要下面的python脚本文件帮我们转换label。

`wget https://pjreddie.com/media/files/voc_label.py`

这里需要修改两个地方，sets和classes，classes根据自己需要修改。

![img](https://img-blog.csdnimg.cn/2018121222592570.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIxNTc4ODQ5,size_16,color_FFFFFF,t_70)

将该文件与VOCdevkit文件夹放在同一目录下，接下来运行该文件，

`python voc_label.py`

我们的目录下会生成三个txt文件2007_train.txt,2007_val.txt,2007_test.txt，VOCdevkit下的VOC2007也会多生成一个labels文件夹，下面是真正会使用到的label，点开看发现已经转化成YOLOV3需要的格式了。这时候自己的数据集正式完成。

`cat 2007_train.txt 2007_val.txt  > train.txt`

此时会发现darknet目录下出现了一个train.txt文件

**6.修改训练置文件：**

修改cfg/voc.data文件：

`gedit cfg/voc.data`

***

`classes= 2   #你的数据及类别 `

`train  = /home/pxt/darknet/train.txt   #上步产生的train.txt文件路径    valid  = /home/pxt/darknet/test.txt    #上步生成的test.txt文件路径 `

`names = data/voc.names backup = backup`

***

修改voc.names文件：

`gedit data/voc.names`

***

`man   #自己的数据集标签 `

`woman`

***

修改cfg/yolov3-voc.cfg文件：

`gedit cfg/yolov3-voc.cfg`

开头部分：

***

`# Testing `

`#batch=1    #注释测试 `

`#subdivisions=1 `

`# Training `

`batch=32    #取消测试，现存小的话将batch改小，subdivisions变大 subdivisions=16`

***

然后，ctrl+f搜 yolo, 总共会搜出3个含有yolo的地方。

这三个地方作相同的更改，每个地方都必须要改2处， 

filters：3*（5+len（classes））         ##(类别数+5) 我的类别是2类，所以是21

classes: len(classes) = 1

可修改：random = 1：原来是1，显存小改为0。（是否要多尺度输出。）

还有另外2处位置都需要作相同修改,可以在gedit下ctrl+f查找yolo找到这三处：

![img](https://img-blog.csdnimg.cn/20181212231521629.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIxNTc4ODQ5,size_16,color_FFFFFF,t_70)

训练前可以修改迭代次数：

`vim yolov3-voc.cfg`

打开文件内容如下：

![屏幕截图 2020-05-19 16:21:06](/home/chen/图片/屏幕截图 2020-05-19 16:21:06.png)

**7.开始训练**

下载预训练权重：

`wget https://pjreddie.com/media/files/darknet53.conv.74`

等待训练结束后（有时还没等结束模型就开始发散了），因此需要检测各项指标（如loss）是否达到了我们期望的数值，如果没有，要分析为什么。可视化训练过程的中间参数可以帮助我们分析问题。可以直接训练，也可以保存日志，便于损失函数可视化

a直接训练：

`./darknet detector train cfg/voc.data cfg/yolov3-voc.cfg darknet53.conv.74`

b保存日志训练：

`./darknet detector train cfg/tiny-yolo.cfg tiny-yolo_8000.conv.9 2>1 | tee person_train_log.txt`

命令：

`tee person_train_log.txt`

（可视化过程见另一博客）

保存log时会生成两个文件，文件1里保存的是网络加载信息和checkout点保存信息，person_train_log.txt中保存的是训练信息。

训练log中各参数的意义：

Region Avg IOU：平均的IOU，代表预测的bounding box和ground truth的交集与并集之比，期望该值趋近于1。

Class：是标注物体的概率，期望该值趋近于1.

Obj：期望该值趋近于1.

No Obj：期望该值越来越小但不为零.

Avg Recall：期望该值趋近1

avg：平均损失，期望该值趋近于0

rate：当前学习率

训练的模型将保存在darknet/backup路径下

若模型训练一半后中断，想要接着上次的结果继续训练，则可执行如下命令：

`./darknet detector train cfg/voc.data cfg/yolov3-voc.cfg backup/yolov3-voc_20000.weights -gpus 1`

即选用最新保存的模型进行训练，但超过10000次后每10000次才保存一次模型，所以如果上次运行到19999次迭代时中断，则只能从第10000次迭代保存的模型处开始训练，修改保存模型的间隔的方法暂时未找。





















